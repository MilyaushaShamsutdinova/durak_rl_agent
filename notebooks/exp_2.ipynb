{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.environment.durak_env import DurakEnv\n",
    "\n",
    "env = DurakEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DQN agent\n",
    "model = DQN('MultiInputPolicy', env, verbose=1)\n",
    "\n",
    "# Training the agent\n",
    "timesteps = 10000\n",
    "start_time = time.time()\n",
    "\n",
    "model.learn(total_timesteps=timesteps)\n",
    "\n",
    "# Evaluate the agent after training\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Training completed in {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Mean Reward: {mean_reward}, Std Reward: {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "episodes = range(1, 11)\n",
    "rewards = [evaluate_policy(model, env, n_eval_episodes=1)[0] for _ in episodes]\n",
    "\n",
    "plt.plot(episodes, rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Agent Performance Over Episodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Error while checking key=board_state: The observation returned by `reset()` method must be a numpy array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mm:\\python_projects\\durak_rl_agent\\venv\\Lib\\site-packages\\stable_baselines3\\common\\env_checker.py:296\u001b[0m, in \u001b[0;36m_check_returned_values\u001b[1;34m(env, observation_space, action_space)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 296\u001b[0m     \u001b[43m_check_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspaces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mm:\\python_projects\\durak_rl_agent\\venv\\Lib\\site-packages\\stable_baselines3\\common\\env_checker.py:209\u001b[0m, in \u001b[0;36m_check_obs\u001b[1;34m(obs, observation_space, method_name)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_numpy_array_space(observation_space):\n\u001b[1;32m--> 209\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, np\u001b[38;5;241m.\u001b[39mndarray), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe observation returned by `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()` method must be a numpy array\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# Additional checks for numpy arrays, so the error message is clearer (see GH#1399)\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: The observation returned by `reset()` method must be a numpy array",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m env \u001b[38;5;241m=\u001b[39m DurakEnv()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Check the environment for any issues (optional but recommended)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mcheck_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Vectorize the environment (required for parallel processing in Stable Baselines3)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m env \u001b[38;5;241m=\u001b[39m DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: DurakEnv()])\n",
      "File \u001b[1;32mm:\\python_projects\\durak_rl_agent\\venv\\Lib\\site-packages\\stable_baselines3\\common\\env_checker.py:473\u001b[0m, in \u001b[0;36mcheck_env\u001b[1;34m(env, warn, skip_render_check)\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# ============ Check the returned values ===============\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m \u001b[43m_check_returned_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;66;03m# ==== Check the render method and the declared render modes ====\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_render_check:\n",
      "File \u001b[1;32mm:\\python_projects\\durak_rl_agent\\venv\\Lib\\site-packages\\stable_baselines3\\common\\env_checker.py:298\u001b[0m, in \u001b[0;36m_check_returned_values\u001b[1;34m(env, observation_space, action_space)\u001b[0m\n\u001b[0;32m    296\u001b[0m             _check_obs(obs[key], observation_space\u001b[38;5;241m.\u001b[39mspaces[key], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 298\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while checking key=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    300\u001b[0m     _check_obs(obs, observation_space, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Error while checking key=board_state: The observation returned by `reset()` method must be a numpy array"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# Import the Durak environment (assuming it's in the same directory or adjust the import path accordingly)\n",
    "from scr.environment.durak_env import DurakEnv\n",
    "\n",
    "# Create the environment\n",
    "env = DurakEnv()\n",
    "\n",
    "# Check the environment for any issues (optional but recommended)\n",
    "check_env(env, warn=True)\n",
    "\n",
    "# Vectorize the environment (required for parallel processing in Stable Baselines3)\n",
    "env = DummyVecEnv([lambda: DurakEnv()])\n",
    "\n",
    "# Create the model: Proximal Policy Optimization (PPO) algorithm\n",
    "model = PPO('MlpPolicy', env, verbose=1)\n",
    "\n",
    "# Train the model for a specified number of timesteps\n",
    "model.learn(total_timesteps=100000)  # Adjust timesteps as necessary\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"ppo_durak_model\")\n",
    "\n",
    "# To load the model later:\n",
    "# model = PPO.load(\"ppo_durak_model\", env=env)\n",
    "\n",
    "# Test the trained model\n",
    "obs = env.reset()\n",
    "for i in range(100):  # Play 100 steps to test the agent\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()  # Add a render function to visualize the game if needed\n",
    "    if done:\n",
    "        obs = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
